{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter US Airline Sentiment Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to build a model for sentiment analysis based on the Twitter US Airline Datasets.\n",
    "\n",
    "The Twitter US Airline Dataset :\n",
    "* Tweets since Feb 2015 about each of the major US airline (US Airways, Virgin America, Delta, United, American Airlines, Southwest)\n",
    "* Each tweet is classified either positive, negative or neutral.\n",
    "\n",
    "\n",
    "The included features including :\n",
    "- Twitter ID, sentiment confidence score, sentiments, negative reasons, airline name, retweet count, name, tweet text, tweet coordinates, date and time of the tweet, and the location of the tweet.\n",
    "\n",
    "Download dataset from here : https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer #for tokenize text \n",
    "from nltk.stem.snowball import SnowballStemmer # for Stemming word \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import collections\n",
    "from util_gridsearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Import of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import of data\n",
    "df = pd.read_csv('Data/Tweets.csv')\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1- Number of tweets in the datasets:  14640\n",
      "-----------------------------------------------------\n",
      " 2- Number of tweet per type of sentiment :\n",
      "-----------------------------------------------------\n",
      "negative    9178\n",
      "neutral     3099\n",
      "positive    2363\n",
      "Name: airline_sentiment, dtype: int64\n",
      "-----------------------------------------------------\n",
      " 3- The part of each type of sentiment in the dataset:\n",
      "-----------------------------------------------------\n",
      "negative    0.626913\n",
      "neutral     0.211680\n",
      "positive    0.161407\n",
      "Name: airline_sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (' 1- Number of tweets in the datasets: ' ,df.shape[0])\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(' 2- Number of tweet per type of sentiment :')\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(df['airline_sentiment'].value_counts())\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(' 3- The part of each type of sentiment in the dataset:')\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(df['airline_sentiment'].value_counts(normalize=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Text Processing \n",
    "\n",
    "The text processing in this project consist of :\n",
    "\n",
    "- Removing punctuation, tags,emoticons, URL and  hyperlinks (Http..)\n",
    "- Stemming — words are reduced to a root by removing inflection through dropping unnecessary characters, usually a suffix.\n",
    "- Removing stop words — frequent words such as ”the”, ”is”, etc. that do not have specific semantic\n",
    "- Apostrophe: to avoid any word sense disambiguation in text, for example \"n't\" is remplaced by \"not\", and \"'ll\" by \"will\", etc\n",
    "- Removing the name of the Airlines from the text.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Processing(text):\n",
    "#Lower Case\n",
    "    text=text.str.lower()\n",
    "    \n",
    "#Using Regular Expression for removing tags, punctuation, emoticons and URL\n",
    "    text=text.str.replace(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([0-9])\",\"\")\n",
    "    text=text.apply(nltk.word_tokenize)\n",
    "    \n",
    "#Stemming each word \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text=text.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text=text.apply(lambda x: [y for y in x if y not in stopwords])\n",
    "    \n",
    "# removing stopword \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text=text.apply(lambda x: [y for y in x if y not in stopwords])\n",
    "    \n",
    "#removing name of the airlines from text\n",
    "    text=text.replace(\"([^United]+)|([^US]+)|([^Southwest]+)|([^Delta]+)|([^Virgin]+)|([^American]+)\",\"\")\n",
    "    \n",
    "#dictionary consisting of the contraction and the actual value \n",
    "    Apos_dict={\"'s\":\" is\",\"n’t\":\" not\",\"'m\":\" am\",\"'ll\":\" will\", \n",
    "           \"'d\":\" would\",\"'ve\":\" have\",\"’re\":\" are\"} \n",
    "  \n",
    "    #replace the contractions \n",
    "    for key,value in Apos_dict.items(): \n",
    "        if key in text: \n",
    "            text=text.replace(key,value) \n",
    "        \n",
    "# Detokenize cleaned dataframe\n",
    "    text_final = text.str.join(\" \")\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=Text_Processing(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youv ad commerci experi tacki</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>didnt today must mean need take anoth trip</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realli aggress blast obnoxi entertain guest fa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realli big bad thing</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                                               said           neutral\n",
       "1                 plus youv ad commerci experi tacki          positive\n",
       "2         didnt today must mean need take anoth trip           neutral\n",
       "3  realli aggress blast obnoxi entertain guest fa...          negative\n",
       "4                               realli big bad thing          negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view after the text processing\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Extracting features from text file :\n",
    "TfidfVectorizer and CountVectorizer both are methods for converting text data into vectors as model can process only numerical data.\n",
    "\n",
    "- TF-IDF (term frequency - inverse document frequency) : weights the word counts by a measure of how often they appear in the documents\n",
    "- CountVectorizer :count the number of times a word appears in the document\n",
    "\n",
    "Parameters to define : min_df, max_df, Ngram\n",
    "\n",
    "for example\n",
    "* min_df =5 : include words tha occur in at least 5 documents \n",
    "* max_df=0.5: Use those words that occur in a maximum of 50% of the documents\n",
    "* Ngram : takes value of (1,1) or (1,2)\n",
    "\n",
    "#### - Model \n",
    "- Logistic Regression\n",
    "- Naives Bayes \n",
    "\n",
    "\n",
    "#### - Evaluation metrics\n",
    "- Accuracy ratio /classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets : \n",
    "#Test data size is 0.2 i.e. 20% of the data, Train data size is the remaining 80%.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], \n",
    "                                                    df['airline_sentiment'], \n",
    "                                                    random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Training set:  (11712,)\n",
      "The shape of the Test shape:  (2928,)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the Training set: ', X_train.shape)\n",
    "print('The shape of the Test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1- First Model \n",
    "Before Tunning the parameters of the model, let's see the result of a the Logistic Regression and CountVect with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVect with default parameters\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "X_train_count=vect.transform(X_train)\n",
    "X_test_count=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[107mClassification report on Test \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.87      1870\n",
      "     neutral       0.62      0.56      0.59       614\n",
      "    positive       0.73      0.65      0.68       444\n",
      "\n",
      "    accuracy                           0.79      2928\n",
      "   macro avg       0.73      0.70      0.71      2928\n",
      "weighted avg       0.78      0.79      0.78      2928\n",
      "\n",
      "\u001b[107mClassification report on Train \u001b[0m\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.96      0.94      7308\n",
      "     neutral       0.85      0.76      0.80      2485\n",
      "    positive       0.89      0.85      0.87      1919\n",
      "\n",
      "    accuracy                           0.90     11712\n",
      "   macro avg       0.88      0.86      0.87     11712\n",
      "weighted avg       0.90      0.90      0.90     11712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression with default parameter\n",
    "logreg = LogisticRegression().fit(X_train_count, y_train)\n",
    "\n",
    "predicted = logreg.predict(X_test_count)\n",
    "print(\"\\033[107m\"+ \"Classification report on Test \"\"\\033[0m\")\n",
    "print(classification_report(y_test, logreg.predict(X_test_count)))\n",
    "print(\"\\033[107m\"+ \"Classification report on Train \"\"\\033[0m\")\n",
    "print(classification_report(y_train, logreg.predict(X_train_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments : \n",
    "\n",
    "- The accuracy ratio for the train is 90% and 79% for the test, there is an overffirting.\n",
    "- To reduce overffiting, we will try to use regularization l1 or l2.\n",
    "- gridserach is used to find the best parameters for the logisticregression/NaiveBayes/SVM and CountVect/TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[107mModel : LogisticRegression\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time : done in 64.82s\n",
      "\n",
      "Best CV score: 0.78\n",
      "Best parameters set:\n",
      "\tclf__C: 1.6\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__min_df: 6\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.79\n",
      "\n",
      "\n",
      "Train score with best_estimator_: 0.84\n",
      "\n",
      "\n",
      " ** Classification Report Test Data ** \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.93      0.87      1870\n",
      "     neutral       0.67      0.50      0.57       614\n",
      "    positive       0.77      0.60      0.67       444\n",
      "\n",
      "    accuracy                           0.79      2928\n",
      "   macro avg       0.75      0.67      0.70      2928\n",
      "weighted avg       0.78      0.79      0.77      2928\n",
      "\n",
      "** Classification Report Train Data ** \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.95      0.90      7308\n",
      "     neutral       0.79      0.60      0.68      2485\n",
      "    positive       0.84      0.70      0.76      1919\n",
      "\n",
      "    accuracy                           0.84     11712\n",
      "   macro avg       0.83      0.75      0.78     11712\n",
      "weighted avg       0.83      0.84      0.83     11712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'vect__max_df': (0.4,0.5),\n",
    "     'vect__min_df': (6,7),\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__C': (1.2,1.6,1.7),\n",
    "     #'clf__penalty': ('l1','l2')\n",
    "}\n",
    "logreg = LogisticRegression(penalty='l2')\n",
    "#see util_gridsearch.py for the function grid_vect\n",
    "best_mnb_countvect = grid_vect(logreg, parameters_logreg, X_train, y_train, X_test,y_test,model_name='LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3- Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[107mModel : NaiveBayes\u001b[0m\n",
      "-------------------------------------------------------\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   43.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time : done in 44.21s\n",
      "\n",
      "Best CV score: 0.76\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.05\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.77\n",
      "\n",
      "\n",
      "Train score with best_estimator_: 0.82\n",
      "\n",
      "\n",
      " ** Classification Report Test Data ** \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.96      0.85      1870\n",
      "     neutral       0.71      0.36      0.48       614\n",
      "    positive       0.81      0.51      0.63       444\n",
      "\n",
      "    accuracy                           0.77      2928\n",
      "   macro avg       0.76      0.61      0.65      2928\n",
      "weighted avg       0.76      0.77      0.74      2928\n",
      "\n",
      "** Classification Report Train Data ** \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.97      0.89      7308\n",
      "     neutral       0.82      0.50      0.62      2485\n",
      "    positive       0.87      0.69      0.77      1919\n",
      "\n",
      "    accuracy                           0.82     11712\n",
      "   macro avg       0.84      0.72      0.76     11712\n",
      "weighted avg       0.83      0.82      0.81     11712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Parameters for MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "parameters_mnb = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'vect__max_df': (0.5,0.7),\n",
    "     'vect__min_df': (5,7),\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__alpha': (0.001,0.05,0.25),}\n",
    "#see util_gridsearch.py for the function grid_vect\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, y_train, X_test,y_test,model_name='NaiveBayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Conclusion\n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        **Model**\n",
    "        </td>\n",
    "        <td>\n",
    "        **Train Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "        **Test Accuracy**\n",
    "        </td>\n",
    "    </tr>\n",
    "        <td>\n",
    "        Logistic Regression\n",
    "        </td>\n",
    "        <td>\n",
    "        84%\n",
    "        </td>\n",
    "        <td>\n",
    "        79%\n",
    "        </td>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Naives Bayes\n",
    "        </td>\n",
    "        <td>\n",
    "        82%\n",
    "        </td>\n",
    "        <td>\n",
    "        77%\n",
    "        </td>\n",
    "    </tr>\n",
    "    \n",
    "</table> \n",
    "\n",
    "The Logistic Regression with CountVectorizer reduces the overfitting and acheive a Accuracy ratio 79% on test set, we select this model for prediction\n",
    "\n",
    "The performance of the model may be improved :\n",
    "- Adding new features : number of word in the text, number of punctuation, etc..\n",
    "- Using Deep Learning approach \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2665"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameters for the best model \n",
    "model=LogisticRegression(penalty='l2',C=1.6)\n",
    "\n",
    "vect = CountVectorizer(analyzer='word',  min_df=6,max_df=0.4,ngram_range=(1, 2),stop_words='english').fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.6, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vect.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vect.get_feature_names()\n",
    "df_features = pd.DataFrame({'coef':model.coef_[0],'names':names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Smallest Coefs :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-2.415421</td>\n",
       "      <td>appl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>-2.133697</td>\n",
       "      <td>kudo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>-2.079267</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>-2.031248</td>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>-1.985774</td>\n",
       "      <td>visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>-1.959276</td>\n",
       "      <td>discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-1.904039</td>\n",
       "      <td>id like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-1.875334</td>\n",
       "      <td>dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>-1.861136</td>\n",
       "      <td>flyingitforward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>-1.855351</td>\n",
       "      <td>golf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef            names\n",
       "133  -2.415421             appl\n",
       "1353 -2.133697             kudo\n",
       "2283 -2.079267            thank\n",
       "725  -2.031248            excel\n",
       "2493 -1.985774            visit\n",
       "600  -1.959276         discount\n",
       "1230 -1.904039          id like\n",
       "512  -1.875334              dal\n",
       "968  -1.861136  flyingitforward\n",
       "1041 -1.855351             golf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The Smallest Coefs :')\n",
    "df_features.sort_values(by='coef',ascending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Largest Coefs :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>3.452032</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2.574707</td>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2.499321</td>\n",
       "      <td>communic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2.487044</td>\n",
       "      <td>ridicul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2.344507</td>\n",
       "      <td>suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2.334466</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>2.324640</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2.319076</td>\n",
       "      <td>screw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2.247134</td>\n",
       "      <td>unless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>2.242092</td>\n",
       "      <td>miser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coef      names\n",
       "2615  3.452032      worst\n",
       "1005  2.574707       fuck\n",
       "424   2.499321   communic\n",
       "1974  2.487044    ridicul\n",
       "2224  2.344507       suck\n",
       "433   2.334466  complaint\n",
       "1394  2.324640        lie\n",
       "2025  2.319076      screw\n",
       "2455  2.247134     unless\n",
       "1549  2.242092      miser"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The Largest Coefs :')\n",
    "df_features.sort_values(by='coef',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for new tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    thank amaz custom support team tuesday return ...\n",
       "1     love fli guy ask year sad last trip luxurytravel\n",
       "2                      wow plane nice clean enjoy trip\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_positive_tweets = pd.Series([\"Thank you @VirginAmerica for you amazing customer support team on Tuesday and returning my lost bag in less than 24h! #efficiencyiskey #virginamerica\"\n",
    "                      ,\"Love flying with you guys ask these years.  Sad that this will be the last trip 😂   @VirginAmerica  #LuxuryTravel\"\n",
    "                      ,\"Wow @VirginAmerica This plane is nice and clean & I have enjoyed the trip \"])\n",
    "new_positive_tweets= Text_Processing(new_positive_tweets)\n",
    "new_positive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(new_positive_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_negative_tweets = pd.Series([\"@VirginAmerica shocked my initially with the service, but then went on to shock me further with no response to what my complaint was. #unacceptable @Delta @richardbranson\"\n",
    "                      ,\"@VirginAmerica this morning I was forced to repack a suitcase w a medical device because it was barely overweight - wasn't even given an option to pay extra. My spouses suitcase then burst at the seam with the added device and had to be taped shut. Awful experience so far!\"\n",
    "                      ,\"Board airplane home. Computer issue. Get off plane, traverse airport to gate on opp side. Get on new plane hour later. Plane too heavy. 8 volunteers get off plane. Ohhh the adventure of travel\"])\n",
    "new_negative_tweets= Text_Processing(new_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(vect.transform(new_negative_tweets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
